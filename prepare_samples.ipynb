{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CFT2018 contest - Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-28T15:08:15.854467Z",
     "start_time": "2018-09-28T15:08:15.317837Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-28T15:08:26.273114Z",
     "start_time": "2018-09-28T15:08:15.857122Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(data_dir+'/train.csv')\n",
    "test = pd.read_csv(data_dir+'/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-28T15:08:26.288188Z",
     "start_time": "2018-09-28T15:08:26.275455Z"
    }
   },
   "outputs": [],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-28T15:08:26.337147Z",
     "start_time": "2018-09-28T15:08:26.299567Z"
    }
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-28T15:08:26.359745Z",
     "start_time": "2018-09-28T15:08:26.340957Z"
    }
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RU & EN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_01 = train[np.logical_or(train.target==0,train.target==1)].reset_index(drop=True)\n",
    "print(train_01.shape)\n",
    "train_01.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проверим, что нет косяков с раскладкой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def layout(fio):\n",
    "    fio = re.sub('[^А-ЯA-Z Ё]','',fio.upper())\n",
    "    if len(re.sub('[А-Я Ё]','',fio)) == 0:\n",
    "        return 'RU'\n",
    "    elif len(re.sub('[A-Z ]','',fio)) == 0:\n",
    "        return 'EN'\n",
    "    else:\n",
    "        return 'RU-EN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_01_lay = train_01\n",
    "train_01_lay['fullname_lay'] = train_01['fullname'].apply(layout)\n",
    "train_01_lay['fullname_true_lay'] = np.nan\n",
    "train_01_lay.loc[~pd.isnull(train_01_lay['fullname_true']),'fullname_true_lay'] = train_01.loc[~pd.isnull(train_01_lay['fullname_true']),'fullname_true'].apply(layout)\n",
    "print(train_01_lay.shape)\n",
    "train_01_lay.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_01_lay.fullname_lay.value_counts())\n",
    "print(train_01_lay.fullname_true_lay.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_01_lay[np.logical_and(train_01_lay.fullname_lay=='RU',train_01_lay.fullname_true_lay=='RU-EN')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_01_ru = train_01_lay[np.multiply(train_01_lay.fullname_lay=='RU',np.logical_or(train_01_lay.fullname_true_lay=='RU',pd.isnull(train_01_lay.fullname_true_lay)))]\n",
    "train_01_ru_train = train_01_ru[:int(0.8*len(train_01_ru))]\n",
    "train_01_ru_valid = train_01_ru[int(0.8*len(train_01_ru)):]\n",
    "\n",
    "print(train_01_ru_train.shape)\n",
    "train_01_ru_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "def encode(fullname, fullname_true):\n",
    "    fullname = '#' + fullname + \"#\"\n",
    "    fullname_true = '#' + fullname_true + \"#\"\n",
    "    target = [''] * len(fullname)\n",
    "    edit_opts = Levenshtein.editops(fullname, fullname_true)\n",
    "    edit_opts = sorted(edit_opts, key=lambda x: (x[0], -x[1]), reverse=True)\n",
    "    for op, src, dst in edit_opts:\n",
    "        if op == 'delete':\n",
    "            target[src] = '--'\n",
    "        if op == 'replace':\n",
    "            target[src] = fullname_true[dst]\n",
    "        if op == 'insert':\n",
    "            target[src] = '+' + fullname_true[dst]\n",
    "    return target\n",
    "\n",
    "def restore(fullname, target):\n",
    "    fullname = '#' + fullname + \"#\"\n",
    "    res = []\n",
    "    for src, tg in zip(fullname, target):\n",
    "        if tg == '':\n",
    "            res.append(src)\n",
    "        elif tg == '--':\n",
    "            pass\n",
    "        elif len(tg) ==2 and tg[0] == '+':\n",
    "            res.append(tg[1])\n",
    "            res.append(src)\n",
    "        else:\n",
    "            res.append(tg)\n",
    "    res = ''.join(res)\n",
    "    return res.strip('#')\n",
    "\n",
    "def errors(fullname, fullname_true):\n",
    "    fullname = '#' + fullname + \"#\"\n",
    "    fullname_true = '#' + fullname_true + \"#\"\n",
    "    target = []\n",
    "    edit_opts = Levenshtein.editops(fullname_true, fullname)\n",
    "    edit_opts = sorted(edit_opts, key=lambda x: (x[0], -x[1]), reverse=True)\n",
    "    for op, src, dst in edit_opts:\n",
    "        if op == 'delete':\n",
    "            target.append(fullname_true[src]+'>--')\n",
    "        if op == 'replace':\n",
    "            target.append(fullname_true[src]+'>'+fullname[dst])\n",
    "        if op == 'insert':\n",
    "            target.append(fullname_true[src]+'>'+fullname[dst]+fullname_true[src])\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_01_ru_error = train_01_ru_train[train_01_ru_train.target==1].reset_index(drop=True)\n",
    "\n",
    "dict_err = dict()\n",
    "\n",
    "for itr in range(len(train_01_ru_error)):\n",
    "    for err in errors(train_01_ru_error.fullname[itr],train_01_ru_error.fullname_true[itr]):\n",
    "        fr, to = err.split('>')\n",
    "        if fr not in dict_err:\n",
    "            dict_err[fr] = defaultdict(int)\n",
    "            dict_err[fr][to] += 1\n",
    "        else:\n",
    "            dict_err[fr][to] += 1\n",
    "\n",
    "dict_sum_freq = {fr:sum(dict_err[fr].values()) for fr in dict_err}\n",
    "dict_err_freq = {fr:{to:dict_err[fr][to]/dict_sum_freq[fr] for to in dict_err[fr]} for fr in dict_err}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "def make_error(fullname_true, dict_err_freq=dict_err_freq):\n",
    "    fullname_true = fullname_true + '#'\n",
    "    err_place = random.randint(0,len(fullname_true)-1)\n",
    "    err_variation = dict_err_freq[fullname_true[err_place]]\n",
    "    err = random.choices(list(err_variation.keys()), list(err_variation.values()))[0]\n",
    "    if err == '--':\n",
    "        fullname_error = fullname_true[:err_place] + fullname_true[err_place+1:]\n",
    "    else:\n",
    "        fullname_error = fullname_true[:err_place] + err + fullname_true[err_place+1:]\n",
    "    \n",
    "    return re.sub('#','',fullname_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullname_true_ru = list(train_01_ru_train.loc[train_01_ru_train.target==0,'fullname']) + list(train_01_ru_train.loc[train_01_ru_train.target==1,'fullname_true'])\n",
    "\n",
    "train_01_ru_augment = pd.DataFrame.from_dict({'fullname_true':fullname_true_ru})\n",
    "train_01_ru_augment['fullname'] = np.nan\n",
    "train_01_ru_augment['country'] = np.nan\n",
    "train_01_ru_augment['target'] = 1\n",
    "train_01_ru_augment['fullname'] = train_01_ru_augment['fullname_true'].apply(make_error)\n",
    "train_01_ru_augment = train_01_ru_augment[['fullname','country','target','fullname_true']]\n",
    "print(train_01_ru_augment.shape)\n",
    "train_01_ru_augment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_01_ru_full = train_01_ru_train[['fullname','country','target','fullname_true']].append(train_01_ru_augment)\n",
    "train_01_ru_full = train_01_ru_full.sample(frac=1).reset_index(drop=True)\n",
    "train_01_ru_full['id'] = train_01_ru_full.index + 1\n",
    "train_01_ru_full = train_01_ru_full[['id','fullname','country','target','fullname_true']]\n",
    "print(train_01_ru_full.shape)\n",
    "print(train_01_ru_full.target.value_counts())\n",
    "train_01_ru_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.to_csv(train_01_ru_full, data_dir+'/train_ru_aug.csv',index=None)\n",
    "pd.DataFrame.to_csv(train_01_ru_valid[['id','fullname','country','target','fullname_true']], data_dir+'/valid_ru.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_01_en = train_01_lay[np.logical_and(train_01_lay.fullname_lay=='EN',np.logical_or(train_01_lay.fullname_true_lay=='EN',pd.isnull(train_01_lay.fullname_true_lay)))].reset_index(drop=True)\n",
    "train_01_en = train_01_en[['id','fullname','country','target','fullname_true']]\n",
    "\n",
    "print(train_01_en.shape)\n",
    "train_01_en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_01_en.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_01_en_train = train_01_en[:int(0.8*len(train_01_en))].reset_index(drop=True)\n",
    "train_01_en_valid = train_01_en[int(0.8*len(train_01_en)):].reset_index(drop=True)\n",
    "print(train_01_en_train.shape,train_01_en_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "def encode(fullname, fullname_true):\n",
    "    fullname = '#' + fullname + \"#\"\n",
    "    fullname_true = '#' + fullname_true + \"#\"\n",
    "    target = [''] * len(fullname)\n",
    "    edit_opts = Levenshtein.editops(fullname, fullname_true)\n",
    "    edit_opts = sorted(edit_opts, key=lambda x: (x[0], -x[1]), reverse=True)\n",
    "    for op, src, dst in edit_opts:\n",
    "        if op == 'delete':\n",
    "            target[src] = '--'\n",
    "        if op == 'replace':\n",
    "            target[src] = fullname_true[dst]\n",
    "        if op == 'insert':\n",
    "            target[src] = '+' + fullname_true[dst]\n",
    "    return target\n",
    "\n",
    "def restore(fullname, target):\n",
    "    fullname = '#' + fullname + \"#\"\n",
    "    res = []\n",
    "    for src, tg in zip(fullname, target):\n",
    "        if tg == '':\n",
    "            res.append(src)\n",
    "        elif tg == '--':\n",
    "            pass\n",
    "        elif len(tg) ==2 and tg[0] == '+':\n",
    "            res.append(tg[1])\n",
    "            res.append(src)\n",
    "        else:\n",
    "            res.append(tg)\n",
    "    res = ''.join(res)\n",
    "    return res.strip('#')\n",
    "\n",
    "def errors(fullname, fullname_true):\n",
    "    fullname = '#' + fullname + \"#\"\n",
    "    fullname_true = '#' + fullname_true + \"#\"\n",
    "    target = []\n",
    "    edit_opts = Levenshtein.editops(fullname_true, fullname)\n",
    "    edit_opts = sorted(edit_opts, key=lambda x: (x[0], -x[1]), reverse=True)\n",
    "    for op, src, dst in edit_opts:\n",
    "        if op == 'delete':\n",
    "            target.append(fullname_true[src]+'>--')\n",
    "        if op == 'replace':\n",
    "            target.append(fullname_true[src]+'>'+fullname[dst])\n",
    "        if op == 'insert':\n",
    "            target.append(fullname_true[src]+'>'+fullname[dst]+fullname_true[src])\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_01_en_error = train_01_en_train[train_01_en_train.target==1].reset_index(drop=True)\n",
    "\n",
    "dict_err = dict()\n",
    "\n",
    "for itr in range(len(train_01_en_error)):\n",
    "    for err in errors(train_01_en_error.fullname[itr],train_01_en_error.fullname_true[itr]):\n",
    "        fr, to = err.split('>')\n",
    "        if fr not in dict_err:\n",
    "            dict_err[fr] = defaultdict(int)\n",
    "            dict_err[fr][to] += 1\n",
    "        else:\n",
    "            dict_err[fr][to] += 1\n",
    "\n",
    "dict_sum_freq = {fr:sum(dict_err[fr].values()) for fr in dict_err}\n",
    "dict_err_freq = {fr:{to:dict_err[fr][to]/dict_sum_freq[fr] for to in dict_err[fr]} for fr in dict_err}\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "def make_error(fullname_true, dict_err_freq=dict_err_freq):\n",
    "    fullname_true = fullname_true + '#'\n",
    "    err_place = random.randint(0,len(fullname_true)-1)\n",
    "    err_variation = dict_err_freq[fullname_true[err_place]]\n",
    "    err = random.choices(list(err_variation.keys()), list(err_variation.values()))[0]\n",
    "    if err == '--':\n",
    "        fullname_error = fullname_true[:err_place] + fullname_true[err_place+1:]\n",
    "    else:\n",
    "        fullname_error = fullname_true[:err_place] + err + fullname_true[err_place+1:]\n",
    "    \n",
    "    return re.sub('#','',fullname_error)\n",
    "\n",
    "fullname_true_en = list(train_01_en_train.loc[train_01_en_train.target==0,'fullname']) + list(train_01_en_train.loc[train_01_en_train.target==1,'fullname_true'])\n",
    "\n",
    "train_01_en_augment = pd.DataFrame.from_dict({'fullname_true':fullname_true_en})\n",
    "train_01_en_augment['fullname'] = np.nan\n",
    "train_01_en_augment['country'] = np.nan\n",
    "train_01_en_augment['target'] = 1\n",
    "train_01_en_augment['fullname'] = train_01_en_augment['fullname_true'].apply(make_error)\n",
    "train_01_en_augment['id'] = train_01_en_augment.index + 1\n",
    "train_01_en_augment = train_01_en_augment[['id','fullname','country','target','fullname_true']]\n",
    "print(train_01_en_augment.shape)\n",
    "train_01_en_augment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transliterate\n",
    "\n",
    "def translit(ru):\n",
    "    return re.sub(\"'\",'',transliterate.translit(ru, 'ru', reversed=True).upper())\n",
    "\n",
    "\n",
    "train_01_en_translit = train_01_ru.copy()\n",
    "train_01_en_translit.fullname = train_01_en_translit.fullname.apply(translit)\n",
    "train_01_en_translit.loc[~pd.isnull(train_01_en_translit.fullname_true),'fullname_true'] = train_01_en_translit.loc[~pd.isnull(train_01_en_translit.fullname_true),'fullname_true'].apply(translit)\n",
    "print(train_01_en_translit.shape)\n",
    "train_01_en_translit.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_01_en_full = train_01_en_train.append([train_01_en_augment, train_01_en_translit[['id','fullname','country','target','fullname_true']]])\n",
    "train_01_en_full = train_01_en_full.sample(frac=1).reset_index(drop=True)\n",
    "train_01_en_full['id'] = train_01_en_full.index + 1\n",
    "print(train_01_en_full.shape)\n",
    "print(train_01_en_full.target.value_counts())\n",
    "train_01_en_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.to_csv(train_01_en_full,data_dir+'/train_en_aug.csv',index=False)\n",
    "pd.DataFrame.to_csv(train_01_en_valid,data_dir+'/valid_en.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nteract": {
   "version": "0.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
